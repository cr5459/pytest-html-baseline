Metadata-Version: 2.4
Name: pytest-snap
Version: 0.1.0
Summary: Pytest plugin for snapshotting test outcomes & performance with rich diffs (failures, xfail transitions, flakiness, performance)
Author: pytest-snap maintainers
License: MIT
Keywords: pytest,plugin,snapshot,baseline,regression,performance,ci
Classifier: Framework :: Pytest
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Operating System :: OS Independent
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Testing
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pytest>=7.0
Provides-Extra: html
Requires-Dist: pytest-html>=4.0; extra == "html"
Provides-Extra: test
Requires-Dist: pytest>=7.0; extra == "test"
Requires-Dist: pytest-html>=4.0; extra == "test"
Requires-Dist: hypothesis>=6.0; extra == "test"
Requires-Dist: PyYAML>=6.0; extra == "test"
Provides-Extra: dev
Requires-Dist: psutil>=5.9; extra == "dev"
Requires-Dist: hypothesis>=6.0; extra == "dev"
Requires-Dist: pytest-html>=4.0; extra == "dev"
Requires-Dist: pytest>=7.0; extra == "dev"
Requires-Dist: PyYAML>=6.0; extra == "dev"
Dynamic: license-file

# pytest-snap

A lightweight way to record the results of a test run (a snapshot) and later compare new runs against that baseline. It highlights regressions (new failures), fixes, removed tests, performance slow‑downs, flaky behavior, and optional performance budget breaches.

The project provides:

1. A pytest plugin (auto‑loaded once installed).  
2. A helper CLI (`pytest-snap`) for labeled runs and offline diffs.

Use either one or both— they are complementary but independent.

---

## Installation

```bash
pip install pytest-snap
```

Verify installation (options now expose both --snap-* and legacy --html-* aliases):

```bash
pytest -h | grep html-baseline
```

---

## Quick Start

1. Create a baseline snapshot:
	```bash
	pytest --snap-save-baseline .artifacts/snap_base.json
	```
2. Later, compare a new run to that baseline:
	```bash
	pytest --snap-baseline .artifacts/snap_base.json
	```
3. End-of-run summary example:
	```
	[pytest-snap] new_failures=1 fixed=2 slower=3 ...
	```
4. Fail the run on slower tests instead of only new failures:
	```bash
	pytest --snap-baseline .artifacts/snap_base.json --snap-fail-on slower
	```
5. (Optional) Use legacy flags if migrating (still supported):
	```bash
	pytest --html-save-baseline .artifacts/snap_base.json   # legacy alias
	```

Updating the baseline: rerun with `--html-save-baseline` pointing at the same file once you accept current results.

---

## Helper CLI (`pytest-snap`)

Labeled runs make comparisons simple (e.g. `v1`, `v2`).

```bash
# Run default sequence (v1 v2 v3)
pytest-snap all

# Or run individual labels
pytest-snap run v1
pytest-snap run v2

# Compare two snapshots (v1 -> v2) with performance analysis
pytest-snap diff v1 v2 --perf

# Show a single snapshot summary
pytest-snap show v2

# Remove generated artifacts
pytest-snap clean
```

Snapshots live in `.artifacts/` as `snap_<label>.json`. Add `--html` to `run`/`all` to also emit a pytest-html report (if `pytest-html` is installed). The CLI is unchanged by the flag rename.

---

## Tracked Change Categories

| Category | Description |
|----------|-------------|
| New failures | Tests that now fail but did not previously |
| Fixed failures | Tests that failed before and now pass |
| Vanished failures | Former failing tests that are now gone or fixed |
| Slower tests | Same test now significantly slower |
| Flaky suspects | Tests whose outcome flips between runs |
| New / resolved / persistent xfails | Expected-failure state transitions |
| XPASS | Tests marked xfail that unexpectedly passed |
| Budget violations | Defined performance budget exceeded |

---

## Performance Budgets (Optional)

Define timing expectations for groups of tests using a YAML file. Example `budgets.yaml`:

```yaml
groups:
  core:
	 match: "tests/"   # substring match in test id
	 p95: 0.50         # 95th percentile < 0.50s
  slow_group:
	 match: "tests/slow_"
	 max_avg: 1.2      # mean duration < 1.2s
```

Use it:
```bash
pytest --snap-baseline .artifacts/snap_base.json \
	--snap-budgets budgets.yaml \
	--snap-fail-on budgets
```
Legacy form (still accepted): `--html-baseline ... --html-budgets ... --html-fail-on budgets`.

---

## Common Options

| Option (preferred) | Legacy alias | Purpose |
|--------------------|-------------|---------|
| `--snap-save-baseline FILE` | `--html-save-baseline` | Write a snapshot for this run |
| `--snap-baseline FILE` | `--html-baseline` | Compare against existing snapshot |
| `--snap-fail-on {new-failures,slower,budgets,any}` | `--html-fail-on` | Choose failure gating mode |
| `--snap-slower-threshold-ratio 1.30` | `--html-slower-threshold-ratio` | Ratio factor to flag slower tests |
| `--snap-slower-threshold-abs 0.20` | `--html-slower-threshold-abs` | Absolute seconds threshold (must also exceed) |
| `--snap-flake-threshold 0.15` | `--html-flake-threshold` | Filter out likely flaky tests above score |
| `--snap-history-path PATH` | `--html-history-path` | Enable rolling history for flake scoring |
| `--snap-history-max N` | `--html-history-max` | Max retained history lines |
| `--snap-diff-json FILE` | `--html-diff-json` | Export structured diff JSON |
| `--snap-budgets FILE` | `--html-budgets` | Performance budgets spec |
| `--snap-verbose` | `--html-baseline-verbose` | Extra console diff details |
| `--snap-badges` | `--html-baseline-badges` | Annotate pytest-html rows |

Recommendation: start with `--snap-save-baseline` then add gating. `--html-*` flags are deprecated and will be removed in a future major release.

---

## Flaky Detection

When history logging is enabled (default in `pytest-snap run`), previous outcomes are tracked. A weighted score measures pass ↔ fail flips. Highly flaky tests can be excluded from "new failures" to reduce noise.

---

## Conceptual Model

1. Capture a baseline snapshot.  
2. Compare new runs to that baseline.  
3. Choose gating rules.  
4. Refresh the baseline when the current state is the new normal.  

---

## FAQ

**Do I need the CLI?** No. The plugin alone works; the CLI adds convenience for labeled runs and offline diffs.

**When do I refresh the baseline?** After intentional changes when remaining differences are acceptable.

**What about flaky tests?** Fix them ideally; meanwhile history-based filtering reduces false alarms.

**Is this a snapshot testing library for function outputs?** No. It snapshots test outcomes and timings.

**Does it speed up tests?** No—it surfaces regressions sooner.

**How do I import programmatically now?**
```python
import pytest_snap
from pytest_snap.diff import diff_snapshots
```
Legacy imports (`import pytest_html_baseline`) still work but emit a deprecation warning.

---

## Glossary

| Term | Definition |
|------|------------|
| Snapshot | JSON record of one full test run |
| Baseline | The snapshot future runs are compared against |
| Diff | Structured comparison of baseline vs current run |
| Flaky test | Test with unstable pass/fail result across runs |
| Budget | Performance rule (e.g. max average or p95) |

---

## Contributing

1. Fork / clone.  
2. (Optional) Create venv & install: `pip install -e .[dev]`.  
3. Add or adjust tests for your changes.  
4. Keep documentation clear and concise.  
5. Open a PR.

---

## License

MIT (see `LICENSE`).

---

Happy testing.

---

### Migration Notes

Version after the rename introduces the new public package name `pytest_snap` and `--snap-*` flags. Old module path `pytest_html_baseline` and `--html-*` flags remain temporarily. Switch to the new names to avoid future breakage.

